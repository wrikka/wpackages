[api]
api_key = ""
model = "gpt-4"
max_tokens = 2048
temperature = 0.7

[cache]
enabled = true
max_capacity = 1000
ttl_seconds = 3600

[rate_limit]
enabled = true
capacity = 100
refill_ms = 60000

[streaming]
enabled = true

[context_window]
max_tokens = 4096
